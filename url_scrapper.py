# -*- coding: utf-8 -*-
"""URL_scrapper.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iXYq5R8yOf67DW2eZ-3p8zXYyk_k2wl_
"""

import sys
import requests
from bs4 import BeautifulSoup
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
# Specify the URL you want to scrape
url_to_scrape = sys.argv[1]

# Send an HTTP GET request to the URL
response = requests.get(url_to_scrape,verify=False)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.text, 'html.parser')

# Find all anchor tags (links) in the HTML
valid_urls = []
valid_urls.append(sys.argv[1])
for link in soup.find_all('a'):
    href = link.get('href')
    if href and href.startswith('https'):
        valid_urls.append(href)

# Write the top 5 valid URLs to a text file
with open('test1.txt', 'w') as file:
    for url in valid_urls[:5]:
        file.write(url + '\n')



"""# New Section"""